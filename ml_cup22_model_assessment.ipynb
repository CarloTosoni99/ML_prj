{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66061e1",
   "metadata": {},
   "source": [
    "# Model Assessment and prediction on the blind set #\n",
    "\n",
    "In this last notebook we have loaded the best models generated to find our final model for the ml-cup-22.\n",
    "\n",
    "In particular, we have implemented an ensembling method using the best model generated during the model selection.\n",
    "\n",
    "These are the models that we considered:\n",
    "\n",
    "1. Neural Network (PyTorch, trained performing a grid search)\n",
    "2. Neural Network (Keras, trained performing a random search)\n",
    "\n",
    "for each model we predicted the labels on the blind set, we summed up all the values and we averaged them.\n",
    "\n",
    "### The model assessment was implemented through a hold out ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082783de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import keras.backend as K\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86b9996",
   "metadata": {},
   "source": [
    "## Data normalizer ##\n",
    "\n",
    "Save the info required to normalize the test set at the same way of the design test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3597926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_normalizer(x_data, y_data):\n",
    "    \n",
    "    x_cols = len(x_data[0])\n",
    "    x_min_values = [None]*x_cols\n",
    "    x_max_values = [None]*x_cols\n",
    "    \n",
    "    # save info to normalize the input of the test set\n",
    "    for i in range(x_cols):\n",
    "        col = x_data[:, i]\n",
    "        \n",
    "        max_vl = np.amax(col)\n",
    "        min_vl = np.amin(col)\n",
    "        \n",
    "        x_min_values[i] = min_vl\n",
    "        x_max_values[i] = max_vl\n",
    "        \n",
    "        \n",
    "    y_cols = len(y_data[0])\n",
    "    y_min_values = [None]*y_cols\n",
    "    y_max_values = [None]*y_cols\n",
    "            \n",
    "    # save info to normalize the target of the test set\n",
    "    for i in range(y_cols):\n",
    "        col = y_data[:, i]\n",
    "        \n",
    "        max_vl = np.amax(col)\n",
    "        min_vl = np.amin(col)\n",
    "        \n",
    "        y_min_values[i] = min_vl\n",
    "        y_max_values[i] = max_vl\n",
    "        \n",
    "                \n",
    "    return x_min_values, x_max_values, y_min_values, y_max_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca179321",
   "metadata": {},
   "source": [
    "## Data loader ##\n",
    "\n",
    "Load a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a165f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(local_path):\n",
    "    \n",
    "    # Load the dataset\n",
    "    data = np.loadtxt(local_path, delimiter=\",\", skiprows=1, usecols=range(2,13), dtype='float32')\n",
    "\n",
    "    # divide into input and target\n",
    "    x_data = (data[:, 0:9])\n",
    "    y_data = (data[:, 9:11])\n",
    "    \n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c8d5e3",
   "metadata": {},
   "source": [
    "## Normalize input ##\n",
    "\n",
    "Normalize the input of the test set of the internal model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa494ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_normalizer(x_data_ts, x_min_values, x_max_values):\n",
    "        \n",
    "    x_cols = len(x_data_ts[0])\n",
    "    \n",
    "    # normalize the input of the test set\n",
    "    for i in range(x_cols):        \n",
    "        x_data_ts[:, i] = (x_data_ts[:, i] - x_min_values[i]) / (x_max_values[i] - x_min_values[i])\n",
    "        \n",
    "    \n",
    "    return x_data_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5b4a06",
   "metadata": {},
   "source": [
    "## Denormalize target ##\n",
    "\n",
    "Denormalize the predicted target of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40382005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_denormalizer(y_data_ts, y_min_values, y_max_values):\n",
    "    \n",
    "    y_cols = len(y_data_ts[0])\n",
    "    \n",
    "    # denormalize the predicted target of the test set\n",
    "    for i in range(y_cols):\n",
    "        y_data_ts[:, i] = y_data_ts[:, i] * (y_max_values[i] - y_min_values[i]) + y_min_values[i] \n",
    "        \n",
    "    return y_data_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e255aaf",
   "metadata": {},
   "source": [
    "## PyTorch model ##\n",
    "\n",
    "class for the model of pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f37fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CupNeuralNet(nn.Module):\n",
    "    # define the neural network's structure\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_output):\n",
    "        super(CupNeuralNet, self).__init__()\n",
    "        \n",
    "        self.linears = nn.ModuleList([nn.Linear(input_size, hidden_size)])\n",
    "        self.linears.extend([nn.Linear(hidden_size, hidden_size) for i in range(1, num_layers)])\n",
    "        self.linears.append(nn.Linear(hidden_size, num_output))\n",
    "        \n",
    "    # Forward pass of the neural network\n",
    "    def forward(self, x):\n",
    "        \n",
    "        first = True\n",
    "        for layer in self.linears:\n",
    "            if (first):\n",
    "                first = False\n",
    "            else:\n",
    "                x = nn.functional.relu(x)\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c692dbe",
   "metadata": {},
   "source": [
    "predict the target of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7751f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_target_design(model, design_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        first_iter = True\n",
    "        total_labels = None\n",
    "        for i, (inputs, labels) in enumerate(design_loader):\n",
    "\n",
    "            # forward pass\n",
    "            predicted_labels = model(inputs)\n",
    "            \n",
    "            if first_iter:\n",
    "                first_iter = False\n",
    "                total_labels = predicted_labels\n",
    "            else:\n",
    "                total_labels = torch.cat((total_labels, predicted_labels), 0)\n",
    "    \n",
    "    return total_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413737e6",
   "metadata": {},
   "source": [
    "the class CupDataset has been used to create a valid dataset (for the ML cup) for the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b36fa92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the ML cup's dataset\n",
    "class CupDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        # division between training and validation\n",
    "        data_x = (data[:, 0:9])\n",
    "        data_y = (data[:, 9:11])\n",
    "                \n",
    "        # conversion from numpy array to tensor\n",
    "        self.x = torch.from_numpy(data_x)\n",
    "        self.y = torch.from_numpy(data_y)\n",
    "        \n",
    "        # convert to float32\n",
    "        self.x = self.x.to(torch.float32)\n",
    "        self.y = self.y.to(torch.float32)\n",
    "        \n",
    "        # save the number of patterns in the training/validation set\n",
    "        self.n_samples = data_x.shape[0]\n",
    "        \n",
    "    # return a specific tensor\n",
    "    def __getitem__ (self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    # return the total number of patterns\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d196c1",
   "metadata": {},
   "source": [
    "Create a dataloader for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c06987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_dataloaders(test_set):\n",
    "        \n",
    "    # create a pytorch dataset for the test set\n",
    "    dataset_ts = CupDataset(test_set)\n",
    "    dataloader_ts = DataLoader(dataset=test_set, batch_size=len(test_set), shuffle=False)\n",
    "\n",
    "    \n",
    "    return dataloader_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a2e61",
   "metadata": {},
   "source": [
    "Compute the labels predicted by the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "476e3c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_target_design(model, test_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        first_iter = True\n",
    "        total_labels = None\n",
    "        \n",
    "        start_iter = iter(test_loader)\n",
    "        group = next(start_iter)\n",
    "        group_x = group[:, 0:9]\n",
    "\n",
    "        # forward pass\n",
    "        predicted_labels = model(group_x)\n",
    "            \n",
    "        return predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf57759",
   "metadata": {},
   "source": [
    "Compute the mean Euclidean error on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6f1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_euclidean_distance(set1, set2):\n",
    "\n",
    "    set1 = torch.from_numpy(set1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        tot_patt = len(set1)\n",
    "        \n",
    "        euclidean_distance = (set1 - set2).pow(2).sum(1).sqrt().sum()\n",
    "\n",
    "        mean_euclidean_distance = euclidean_distance / tot_patt\n",
    "\n",
    "        return mean_euclidean_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a66ab",
   "metadata": {},
   "source": [
    "## Keras ##\n",
    "\n",
    "Redefine the used metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "387f2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the mean euclidean distance for Keras\n",
    "def euclidean_distance(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    mean Euclidean distance error\n",
    "    :param y_true: TensorFlow/Theano tensor\n",
    "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    return (K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4052b69",
   "metadata": {},
   "source": [
    "## Test Set ##\n",
    "\n",
    "loading the test set and the selected models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7818b8f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot parse keras metadata at path results/ml_cup/nn_RandomSearch/avg_model_double_layer/keras_metadata.pb: Received error: Field number 0 is illegal.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m model_pt\u001b[38;5;241m.\u001b[39meval();\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# loading the keras model\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m model_kr \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path_keras\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meuclidean_distance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43meuclidean_distance\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# loading the krr models\u001b[39;00m\n\u001b[0;32m     37\u001b[0m model_krr_1 \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(local_path_krr_1)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\saving\\saved_model\\load.py:117\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    115\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mParseFromString(file_content)\n\u001b[0;32m    116\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m message\u001b[38;5;241m.\u001b[39mDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    118\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot parse keras metadata at path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_metadata_pb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReceived error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m   logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSavedModel saved prior to TF 2.5 detected when loading \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    122\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKeras model. Please ensure that you are saving the model \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    123\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwith model.save() or tf.keras.models.save_model(), *NOT* \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    124\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf.saved_model.save(). To confirm, there should be a file \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    125\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamed \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras_metadata.pb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the SavedModel directory.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot parse keras metadata at path results/ml_cup/nn_RandomSearch/avg_model_double_layer/keras_metadata.pb: Received error: Field number 0 is illegal."
     ]
    }
   ],
   "source": [
    "# Local paths where the datasets are stored\n",
    "local_path_tr = './dataset/ml_cup22/ML-CUP22-TR.csv'\n",
    "local_path_ts = './dataset/ml_cup22/ML-CUP22-INTERNAL-TS.csv'\n",
    "local_path_bl = './dataset/ml_cup22/ML-CUP22-TS.csv'\n",
    "\n",
    "# Path where the model of pyTorch is stored\n",
    "local_path_pyTorch = \"./results/ml_cup/nn_GridSearch/avg_model/fm_mlcup.pt\"\n",
    "\n",
    "# Path where the model of keras is stored\n",
    "local_path_keras = \"results/ml_cup/nn_RandomSearch/avg_model_double_layer/\"\n",
    "\n",
    "# Path where the KRR model is stored\n",
    "local_path_krr_1 = \"results/ml_cup/KRR/rbf_krr_1.z\"\n",
    "local_path_krr_2 = \"results/ml_cup/KRR/rbf_krr_2.z\"\n",
    "\n",
    "# loading the training set for the phase of normalization\n",
    "x_data_tr, y_data_tr = load_dataset(local_path_tr)\n",
    "x_min_values, x_max_values, y_min_values, y_max_values = training_normalizer(x_data_tr, y_data_tr)\n",
    "\n",
    "x_data_ts, y_data_ts = load_dataset(local_path_ts)\n",
    "x_data_ts = test_normalizer(x_data_ts, x_min_values, x_max_values)\n",
    "\n",
    "# recreate the dataset\n",
    "data_ts = np.concatenate((x_data_ts, y_data_ts), axis = 1) \n",
    "\n",
    "# create a valid dataloader for the test set\n",
    "dataloader_ts = define_dataloaders(data_ts)\n",
    "\n",
    "# loading the pytorch model\n",
    "model_pt = torch.load(local_path_pyTorch)\n",
    "model_pt.eval();\n",
    "\n",
    "# loading the keras model\n",
    "model_kr = load_model(local_path_keras, custom_objects={\"euclidean_distance\": euclidean_distance})\n",
    "\n",
    "# loading the krr models\n",
    "model_krr_1 = joblib.load(local_path_krr_1)\n",
    "model_krr_2 = joblib.load(local_path_krr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4f54ac",
   "metadata": {},
   "source": [
    "## Predict labels ##\n",
    "\n",
    "At this point we are able for the model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea19357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the result on the internal test set\n",
    "pred_labels_pyTorch = predict_target_design(model_pt, dataloader_ts)\n",
    "pred_labels_keras = model_kr.predict(x_data_ts)\n",
    "pred_label_krr_1 = model_krr_1.predict(x_data_ts)\n",
    "pred_label_krr_2 = model_krr_2.predict(x_data_ts)\n",
    "pred_label_krr = np.concatenate((pred_label_krr_1, pred_label_krr_2), axis = 1)\n",
    "\n",
    "# denormalize the result\n",
    "pred_labels_pyTorch = test_denormalizer(pred_labels_pyTorch, y_min_values, y_max_values)\n",
    "pred_labels_keras = test_denormalizer(pred_labels_keras, y_min_values, y_max_values)\n",
    "pred_label_krr = test_denormalizer(pred_label_krr, y_min_values, y_max_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ba3cf",
   "metadata": {},
   "source": [
    "## Average the results ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8473db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_models = 3\n",
    "pred_labels_ensembling = (pred_labels_pyTorch + pred_labels_keras + pred_label_krr) / num_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fb5704",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "marker_size = 6\n",
    "plt.figure(figsize=(8, 8), dpi=80)\n",
    "plt.scatter(pred_labels_ensembling[:, 0], pred_labels_ensembling[:, 1], s=marker_size, c=\"red\")\n",
    "plt.scatter(y_data_ts[:, 0], y_data_ts[:, 1], s=marker_size, c=\"blue\")\n",
    "\n",
    "legend = [\"predicted targets\", \"real targets\"]\n",
    "plt.legend(legend)\n",
    "\n",
    "plt.title(\"Predicted vs real Target, (test set)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd21f4f0",
   "metadata": {},
   "source": [
    "Now let's see the error on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = compute_mean_euclidean_distance(y_data_ts, pred_labels_ensembling)\n",
    "\n",
    "print(\"The mean Euclidean error of the final model is\", res.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a40df41",
   "metadata": {},
   "source": [
    "## Blind Set ##\n",
    "\n",
    "The last step consists in trying to predict the missing targets of the blind set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load correctly the blind dataset\n",
    "data_blind = np.loadtxt(local_path_bl, delimiter=\",\", dtype='float32')\n",
    "data_blind = data_blind[:, 1:10]\n",
    "\n",
    "# normalize the dataset\n",
    "data_blind = test_normalizer(data_blind, x_min_values, x_max_values)\n",
    "\n",
    "# create a valid dataloader for the blind set\n",
    "dataloader_blind = define_dataloaders(data_blind)\n",
    "\n",
    "# predict the result on the blind set\n",
    "# pyTorch\n",
    "pred_labels_blind_pyTorch = predict_target_design(model_pt, dataloader_blind)\n",
    "# keras\n",
    "pred_labels_blind_keras = model_kr.predict(data_blind)\n",
    "\n",
    "# denormalize the results\n",
    "# pyTorch\n",
    "pred_labels_blind_pyTorch = test_denormalizer(pred_labels_blind_pyTorch, y_min_values, y_max_values)\n",
    "# keras\n",
    "pred_labels_blind_keras = test_denormalizer(pred_labels_blind_keras, y_min_values, y_max_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6364b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 2\n",
    "pred_labels_blind_ensembling = (pred_labels_blind_pyTorch + pred_labels_blind_keras) / num_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd2c56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "marker_size = 6\n",
    "plt.figure(figsize=(8, 8), dpi=80)\n",
    "plt.scatter(pred_labels_blind_ensembling[:, 0], pred_labels_blind_ensembling[:, 1], s=marker_size, c=\"blue\")\n",
    "plt.title(\"predicted labels on the blind set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33cc9f3",
   "metadata": {},
   "source": [
    "# Save #\n",
    "\n",
    "Save the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e550a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the index\n",
    "index = np.zeros((len(pred_labels_blind_ensembling), 1), dtype=int)\n",
    "for i in range(len(index)):\n",
    "    index[i] = i + 1\n",
    "    \n",
    "fin_pred_labels_blind = np.concatenate((index, pred_labels_blind_ensembling), axis=1)\n",
    "\n",
    "# convert to pandas dataframes\n",
    "df_blind = pd.DataFrame(fin_pred_labels_blind)\n",
    "df_blind = df_blind.astype({0:'int'})\n",
    "\n",
    "# local path to save the result on the blind set\n",
    "local_path_blind_pred = './results/ml_cup/blind_set_prediction/F1group_ML-CUP22-TS.csv'\n",
    "\n",
    "# open a new file and write some comments\n",
    "f = open(local_path_blind_pred, 'w')\n",
    "\n",
    "f.write('# Pasquale Esposito - Innocenzo Fulginiti - Carlo Tosoni\\n')\n",
    "f.write('# F1group\\n')\n",
    "f.write('# ML_CUP22\\n')\n",
    "f.write('# 5 dicembre 2022\\n')\n",
    "\n",
    "# save the dataframe as csv\n",
    "df_blind.to_csv(f, header=False, index=False)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a090bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
