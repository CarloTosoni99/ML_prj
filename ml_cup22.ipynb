{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "959a520e",
   "metadata": {},
   "source": [
    "## ADD DESCRIPTION FOR THE PROJECT ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec48d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 17:58:07.911051: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-14 17:58:08.245626: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-14 17:58:08.245647: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-14 17:58:08.298417: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-14 17:58:09.440972: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-14 17:58:09.441528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-14 17:58:09.441537: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import metrics\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643ea4e",
   "metadata": {},
   "source": [
    "Loading data for the ML cup 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96114769",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['id', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'class1', 'class2']\n",
    "mlcup_tr = pd.read_csv(\"./dataset/ml_cup22/ML-CUP22-TR.csv\", sep = \",\", names=colnames)\n",
    "mlcup_tr = mlcup_tr.iloc[7:, :]\n",
    "mlcup_tr = mlcup_tr.drop('id', axis=1)\n",
    "mlcup_tr = (mlcup_tr-mlcup_tr.min())/(mlcup_tr.max()-mlcup_tr.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74946f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mlcup_tr = mlcup_tr.iloc[:, 0:9].values\n",
    "y_mlcup_tr = mlcup_tr.iloc[:, 9:11].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408b07b5",
   "metadata": {},
   "source": [
    "## Neural Network with Random Search ##\n",
    "\n",
    "Below we extended the RandomSearch class of the keras_tuner library to perform a cross validation during the phase of model selection (which is not supported by the RandomSearch class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "07154c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELIMINAREEEEEEEEEEEE\n",
    "X = np.random.random((500, 9))\n",
    "y = np.random.random((500, 2))\n",
    "X_val = np.random.random((100, 9))\n",
    "y_val = np.random.random((100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04af8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidationRandomSearch(kt.RandomSearch):\n",
    "\n",
    "    \n",
    "    cross_validation_partitions = -1\n",
    "    \n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        hypermodel=None,\n",
    "        objective=None,\n",
    "        max_trials=10,\n",
    "        seed=None,\n",
    "        hyperparameters=None,\n",
    "        tune_new_entries=True,\n",
    "        allow_new_entries=True,\n",
    "        folds_number=1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.cross_validation_partitions = model_selection.KFold(folds_number)\n",
    "        \n",
    "        \n",
    "        kt.RandomSearch.__init__(\n",
    "            self,\n",
    "            hypermodel=hypermodel,\n",
    "            objective=objective,\n",
    "            max_trials=max_trials,\n",
    "            seed=seed,\n",
    "            hyperparameters=hyperparameters,\n",
    "            tune_new_entries=tune_new_entries,\n",
    "            allow_new_entries=allow_new_entries,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        \n",
    "    def run_trial(self, trial, x_train, y_train, *args, **kwargs):\n",
    "    \n",
    "        histories_cv = []\n",
    "        histories_folds = []\n",
    "        # build a different model for each fold of the cross validation\n",
    "        for train_indices, test_indices in self.cross_validation_partitions.split(x_train):\n",
    "            x_cv_train, x_cv_val = x_train[train_indices], x_train[test_indices]\n",
    "            y_cv_train, y_cv_val = y_train[train_indices], y_train[test_indices]\n",
    "            histories_folds = super(CrossValidationRandomSearch, self).run_trial(\n",
    "                trial, x_cv_train, y_cv_train, validation_data=(x_cv_val, y_cv_val), *args, **kwargs\n",
    "            )\n",
    "            histories_cv.append(histories_folds)\n",
    "\n",
    "            histories_folds = []\n",
    "        # return the performance of each model\n",
    "        return histories_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7437399",
   "metadata": {},
   "source": [
    "Below we defined two functions; the first one is used to create a model given a combination of hyperparameters, while the second one select a random combination of hyperparameters in a given range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8af9b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a model given a specific combination of hyperparameters\n",
    "def set_hyperparameters(units, ridge_lambda, learning_rate, momentum, double_layer):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=units,\n",
    "            activity_regularizer=regularizers.L2(ridge_lambda),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "    # if double_layer == True, a second layer for the NN is added\n",
    "    if (double_layer):\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=units,\n",
    "                activity_regularizer=regularizers.L2(ridge_lambda),\n",
    "                activation=\"relu\"\n",
    "            )\n",
    "        )\n",
    "    model.add(Dense(2, activation=\"linear\", activity_regularizer=regularizers.L2(ridge_lambda)))\n",
    "    # the optimizer is the stochastic gradient descent algorithm\n",
    "    opt = optimizers.SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    model.compile(\n",
    "        optimizer=opt, loss=\"mean_squared_error\", metrics=[\"mean_absolute_error\"]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# extract a random combination of hyperparamaters\n",
    "def build_regressor(hp, min_units=2, max_units=11, min_ridge_lambda=0.0001, max_ridge_lambda=0.1, min_lr_rate=0.1, \n",
    "                max_lr_rate=0.6, min_mom=0.0, max_mom=0.9, linear_reg=False, double_layer=False):\n",
    "    \n",
    "    ridge_lambda_sampling = \"log\"\n",
    "    if(linear_reg):\n",
    "        ridge_lambda_sampling = \"linear\"\n",
    "    \n",
    "    units_step = 1\n",
    "    if (max_units != min_units):\n",
    "        units_step = 3\n",
    "    \n",
    "    # the variable 'units' represents the number of units of the hidden layer\n",
    "    # by default this value is extracted between 2 and 11 (the user can specify a different interval)\n",
    "    units = hp.Int(\"units\", min_value=min_units, max_value=max_units, step=units_step)\n",
    "    \n",
    "    # the variable 'ridge_lambda' represents the lambda coefficient for ridge regularization\n",
    "    # by default this value is extracted between 0.0001 and 0.1 with a logarithmic probabilistic law\n",
    "    # (the user can specify a different interval)\n",
    "    ridge_lambda = hp.Float(\n",
    "        \"ridge_lambda\", min_value=min_ridge_lambda, max_value=max_ridge_lambda, sampling=ridge_lambda_sampling\n",
    "    )\n",
    "    \n",
    "    # the variable 'learning rate' represents the step used by the stochastic gradient descent algorithm\n",
    "    # by default this value is extracted between 0.1 and 0.6 (the user can specify a different interval)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=min_lr_rate, max_value=max_lr_rate, sampling=\"linear\")\n",
    "    \n",
    "    # the variable 'momentum' represents the coefficient drawn for momentum\n",
    "    # by default this value is extracted between 0.1 and 0.6 (the user can specify a different interval)\n",
    "    momentum = hp.Float(\"momentum\", min_value=min_mom, max_value=max_mom, sampling=\"linear\")\n",
    "    \n",
    "    # Create the model with the set of hyperparameters drew\n",
    "    model = set_hyperparameters(\n",
    "        units=units, ridge_lambda=ridge_lambda, learning_rate=learning_rate, \n",
    "        momentum=momentum, double_layer=double_layer\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6219fe",
   "metadata": {},
   "source": [
    "Let's start searching randomly the best combination of hyperparameters using only one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac90ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = CrossValidationRandomSearch(\n",
    "    hypermodel=build_regressor, # function that return a model given a combination of hyperparameters\n",
    "    objective=kt.Objective(\"val_mean_absolute_error\", direction=\"min\"), # value to minimize\n",
    "    max_trials=50, # maximum number of attempts\n",
    "    executions_per_trial=2, # number of models created for each fold of the cross validation\n",
    "    overwrite=True,\n",
    "    directory=\"results/ml_cup\",\n",
    "    project_name=\"nn_RandomSearch/par_hp\",\n",
    "    folds_number=5 # number of folds of the cross validation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571931a6",
   "metadata": {},
   "source": [
    "print a brief description of the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0dcdfb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 11, 'step': 3, 'sampling': None}\n",
      "ridge_lambda (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.1, 'step': None, 'sampling': 'log'}\n",
      "learning_rate (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.6, 'step': None, 'sampling': 'linear'}\n",
      "momentum (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.9, 'step': None, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6eea5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 00m 45s]\n",
      "val_mean_absolute_error: 0.08996025919914245\n",
      "\n",
      "Best val_mean_absolute_error So Far: 0.06927253715693951\n",
      "Total elapsed time: 00h 04m 05s\n",
      "\n",
      "Search: Running Trial #7\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "8                 |8                 |units\n",
      "0.0010079         |0.0013868         |ridge_lambda\n",
      "0.44811           |0.23573           |learning_rate\n",
      "0.6174            |0.88412           |momentum\n",
      "\n",
      "Epoch 1/1000\n",
      "38/38 [==============================] - 1s 8ms/step - loss: 0.1220 - mean_absolute_error: 0.2550 - val_loss: 0.0667 - val_mean_absolute_error: 0.2128\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0680 - mean_absolute_error: 0.2158 - val_loss: 0.0653 - val_mean_absolute_error: 0.2088\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0680 - mean_absolute_error: 0.2166 - val_loss: 0.0734 - val_mean_absolute_error: 0.2215\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0692 - mean_absolute_error: 0.2178 - val_loss: 0.0669 - val_mean_absolute_error: 0.2194\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0683 - mean_absolute_error: 0.2165 - val_loss: 0.0670 - val_mean_absolute_error: 0.2096\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0682 - mean_absolute_error: 0.2171 - val_loss: 0.0661 - val_mean_absolute_error: 0.2173\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0681 - mean_absolute_error: 0.2165 - val_loss: 0.0727 - val_mean_absolute_error: 0.2220\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0694 - mean_absolute_error: 0.2179 - val_loss: 0.0671 - val_mean_absolute_error: 0.2195\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0681 - mean_absolute_error: 0.2162 - val_loss: 0.0657 - val_mean_absolute_error: 0.2143\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0678 - mean_absolute_error: 0.2157 - val_loss: 0.0673 - val_mean_absolute_error: 0.2060\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0681 - mean_absolute_error: 0.2161 - val_loss: 0.0657 - val_mean_absolute_error: 0.2065\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0681 - mean_absolute_error: 0.2155 - val_loss: 0.0696 - val_mean_absolute_error: 0.2201\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0684 - mean_absolute_error: 0.2168 - val_loss: 0.0658 - val_mean_absolute_error: 0.2148\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0676 - mean_absolute_error: 0.2154 - val_loss: 0.0653 - val_mean_absolute_error: 0.2078\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0682 - mean_absolute_error: 0.2164 - val_loss: 0.0660 - val_mean_absolute_error: 0.2073\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0676 - mean_absolute_error: 0.2155 - val_loss: 0.0661 - val_mean_absolute_error: 0.2051\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0685 - mean_absolute_error: 0.2163 - val_loss: 0.0658 - val_mean_absolute_error: 0.2131\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0675 - mean_absolute_error: 0.2151 - val_loss: 0.0654 - val_mean_absolute_error: 0.2103\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0683 - mean_absolute_error: 0.2162 - val_loss: 0.0738 - val_mean_absolute_error: 0.2226\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0686 - mean_absolute_error: 0.2174 - val_loss: 0.0720 - val_mean_absolute_error: 0.2170\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0692 - mean_absolute_error: 0.2182 - val_loss: 0.0803 - val_mean_absolute_error: 0.2271\n",
      "Epoch 22/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0686 - mean_absolute_error: 0.2170 - val_loss: 0.0715 - val_mean_absolute_error: 0.2268\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0695 - mean_absolute_error: 0.2185 - val_loss: 0.0716 - val_mean_absolute_error: 0.2182\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0678 - mean_absolute_error: 0.2151 - val_loss: 0.0731 - val_mean_absolute_error: 0.2320\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0685 - mean_absolute_error: 0.2168 - val_loss: 0.0678 - val_mean_absolute_error: 0.2235\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0679 - mean_absolute_error: 0.2160 - val_loss: 0.0688 - val_mean_absolute_error: 0.2158\n",
      "Epoch 1/1000\n",
      "38/38 [==============================] - 1s 7ms/step - loss: 0.0443 - mean_absolute_error: 0.1488 - val_loss: 0.0207 - val_mean_absolute_error: 0.1093\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0187 - mean_absolute_error: 0.1041 - val_loss: 0.0182 - val_mean_absolute_error: 0.1007\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0149 - mean_absolute_error: 0.0905 - val_loss: 0.0134 - val_mean_absolute_error: 0.0820\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0126 - mean_absolute_error: 0.0828 - val_loss: 0.0140 - val_mean_absolute_error: 0.0863\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0108 - mean_absolute_error: 0.0757 - val_loss: 0.0130 - val_mean_absolute_error: 0.0842\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0106 - mean_absolute_error: 0.0742 - val_loss: 0.0148 - val_mean_absolute_error: 0.0928\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0734 - val_loss: 0.0272 - val_mean_absolute_error: 0.1187\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0107 - mean_absolute_error: 0.0748 - val_loss: 0.0111 - val_mean_absolute_error: 0.0776\n",
      "Epoch 9/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0096 - mean_absolute_error: 0.0708 - val_loss: 0.0120 - val_mean_absolute_error: 0.0799\n",
      "Epoch 10/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0098 - mean_absolute_error: 0.0719 - val_loss: 0.0103 - val_mean_absolute_error: 0.0746\n",
      "Epoch 11/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0094 - mean_absolute_error: 0.0701 - val_loss: 0.0098 - val_mean_absolute_error: 0.0710\n",
      "Epoch 12/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0095 - mean_absolute_error: 0.0704 - val_loss: 0.0095 - val_mean_absolute_error: 0.0699\n",
      "Epoch 13/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0091 - mean_absolute_error: 0.0692 - val_loss: 0.0116 - val_mean_absolute_error: 0.0819\n",
      "Epoch 14/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0092 - mean_absolute_error: 0.0694 - val_loss: 0.0121 - val_mean_absolute_error: 0.0820\n",
      "Epoch 15/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0097 - mean_absolute_error: 0.0714 - val_loss: 0.0094 - val_mean_absolute_error: 0.0698\n",
      "Epoch 16/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0090 - mean_absolute_error: 0.0686 - val_loss: 0.0135 - val_mean_absolute_error: 0.0839\n",
      "Epoch 17/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0094 - mean_absolute_error: 0.0705 - val_loss: 0.0096 - val_mean_absolute_error: 0.0704\n",
      "Epoch 18/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0093 - mean_absolute_error: 0.0704 - val_loss: 0.0124 - val_mean_absolute_error: 0.0823\n",
      "Epoch 19/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0095 - mean_absolute_error: 0.0712 - val_loss: 0.0115 - val_mean_absolute_error: 0.0795\n",
      "Epoch 20/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0090 - mean_absolute_error: 0.0687 - val_loss: 0.0105 - val_mean_absolute_error: 0.0739\n",
      "Epoch 21/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0094 - mean_absolute_error: 0.0703 - val_loss: 0.0099 - val_mean_absolute_error: 0.0718\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0090 - mean_absolute_error: 0.0687 - val_loss: 0.0123 - val_mean_absolute_error: 0.0853\n",
      "Epoch 23/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_absolute_error: 0.0697 - val_loss: 0.0093 - val_mean_absolute_error: 0.0690\n",
      "Epoch 24/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0090 - mean_absolute_error: 0.0690 - val_loss: 0.0093 - val_mean_absolute_error: 0.0693\n",
      "Epoch 25/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0094 - mean_absolute_error: 0.0701 - val_loss: 0.0105 - val_mean_absolute_error: 0.0763\n",
      "Epoch 26/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0092 - mean_absolute_error: 0.0704 - val_loss: 0.0094 - val_mean_absolute_error: 0.0697\n",
      "Epoch 27/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0088 - mean_absolute_error: 0.0683 - val_loss: 0.0107 - val_mean_absolute_error: 0.0754\n",
      "Epoch 28/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0092 - mean_absolute_error: 0.0698 - val_loss: 0.0092 - val_mean_absolute_error: 0.0691\n",
      "Epoch 29/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_error: 0.0693 - val_loss: 0.0104 - val_mean_absolute_error: 0.0738\n",
      "Epoch 30/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_absolute_error: 0.0683 - val_loss: 0.0111 - val_mean_absolute_error: 0.0762\n",
      "Epoch 31/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0098 - mean_absolute_error: 0.0726 - val_loss: 0.0099 - val_mean_absolute_error: 0.0716\n",
      "Epoch 32/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0088 - mean_absolute_error: 0.0680 - val_loss: 0.0144 - val_mean_absolute_error: 0.0867\n",
      "Epoch 33/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0089 - mean_absolute_error: 0.0688 - val_loss: 0.0115 - val_mean_absolute_error: 0.0822\n",
      "Epoch 1/1000\n",
      "38/38 [==============================] - 1s 6ms/step - loss: 0.0351 - mean_absolute_error: 0.1386 - val_loss: 0.0160 - val_mean_absolute_error: 0.0960\n",
      "Epoch 2/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0137 - mean_absolute_error: 0.0860 - val_loss: 0.0124 - val_mean_absolute_error: 0.0776\n",
      "Epoch 3/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0114 - mean_absolute_error: 0.0758 - val_loss: 0.0099 - val_mean_absolute_error: 0.0680\n",
      "Epoch 4/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0100 - mean_absolute_error: 0.0701 - val_loss: 0.0109 - val_mean_absolute_error: 0.0722\n",
      "Epoch 5/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0096 - mean_absolute_error: 0.0684 - val_loss: 0.0105 - val_mean_absolute_error: 0.0738\n",
      "Epoch 6/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0091 - mean_absolute_error: 0.0664 - val_loss: 0.0088 - val_mean_absolute_error: 0.0627\n",
      "Epoch 7/1000\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_absolute_error: 0.0665 - val_loss: 0.0085 - val_mean_absolute_error: 0.0611\n",
      "Epoch 8/1000\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0084 - mean_absolute_error: 0.0638 - val_loss: 0.0091 - val_mean_absolute_error: 0.0647\n",
      "Epoch 9/1000\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0108 - mean_absolute_error: 0.0781"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    # the training set for the model selection\n",
    "    x_mlcup_tr, y_mlcup_tr,# maximum number of epochs allowed\n",
    "    epochs=1000,\n",
    "    # callback to implement early stopping\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_mean_absolute_error',  patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6040c0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_mlcup_tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20c480c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
